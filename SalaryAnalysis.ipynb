{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "import graphviz\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv as dataframe\n",
    "df_salaries_uncleaned = pd.read_csv(\"data/Salary_Data.csv\")\n",
    "\n",
    "# drop null entries\n",
    "df_salaries_cleaned = df_salaries_uncleaned.dropna()\n",
    "\n",
    "# standardize the degree names\n",
    "df_salaries_cleaned[\"Education Level\"] = df_salaries_cleaned[\"Education Level\"].replace(\"Bachelor's Degree\", \"Bachelor's\")\n",
    "df_salaries_cleaned[\"Education Level\"] = df_salaries_cleaned[\"Education Level\"].replace(\"Master's Degree\", \"Master's\")\n",
    "df_salaries_cleaned[\"Education Level\"] = df_salaries_cleaned[\"Education Level\"].replace(\"phD\", \"PhD\")\n",
    "\n",
    "# normalize data types\n",
    "df_salaries_cleaned[\"Age\"] = df_salaries_cleaned[\"Age\"].astype(\"int\")\n",
    "df_salaries_cleaned[\"Years of Experience\"] = df_salaries_cleaned[\"Years of Experience\"].astype(\"int\")\n",
    "\n",
    "# drop duplicate entries\n",
    "df_salaries_cleaned = df_salaries_cleaned.drop_duplicates()\n",
    "\n",
    "# show data summary\n",
    "df_salaries_cleaned.info()\n",
    "df_salaries_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figue 1: Overall Data Distribution with Histograms\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\n",
    "df_salaries_cleaned[\"Age\"].plot(kind=\"hist\", ax=axes[0, 0], title=\"Age\")\n",
    "df_salaries_cleaned[\"Years of Experience\"].plot(kind=\"hist\", ax=axes[0, 1], title=\"Years of Experience\")\n",
    "df_salaries_cleaned[\"Salary\"].plot(kind=\"hist\", ax=axes[0, 2], title=\"Salary\")\n",
    "df_salaries_cleaned[\"Gender\"].value_counts().plot(kind=\"bar\", ax=axes[1, 0], title=\"Gender\")\n",
    "df_salaries_cleaned[\"Education Level\"].value_counts().plot(kind=\"bar\", ax=axes[1, 1], title=\"Education\")\n",
    "df_salaries_cleaned[\"Job Title\"].value_counts()[:20].plot(kind=\"bar\", ax=axes[1, 2], title=\"Top 20 Job Titles\")\n",
    "fig.suptitle(\"Overall Data Distribution\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Figure 2: Data distribution - Salaries v. one factor\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 7))\n",
    "xfactor = \"Gender\"\n",
    "g = sns.boxplot(x=xfactor, y=\"Salary\", data=df_salaries_cleaned, ax=axes[0, 0], order=df_salaries_cleaned.groupby(xfactor)[\"Salary\"].median().sort_values().index)\n",
    "g.set(title='Gender', xlabel=None)\n",
    "\n",
    "xfactor = \"Education Level\"\n",
    "g = sns.boxplot(x=xfactor, y=\"Salary\", data=df_salaries_cleaned, ax=axes[0, 1], order=df_salaries_cleaned.groupby(xfactor)[\"Salary\"].median().sort_values().index)\n",
    "g.set(title=\"Education Level\", xlabel=None)\n",
    "\n",
    "xfactor = \"Age\"\n",
    "plt.xticks(rotation=90)\n",
    "g = sns.boxplot(x=xfactor, y=\"Salary\", ax=axes[1, 0], data=df_salaries_cleaned)\n",
    "g.set(title=\"Age\", xlabel=None)\n",
    "\n",
    "xfactor = \"Years of Experience\"\n",
    "plt.xticks(rotation=90)\n",
    "g = sns.boxplot(x=xfactor, y=\"Salary\", ax=axes[1, 1], data=df_salaries_cleaned)\n",
    "g.set(title=\"Years of Experience\", xlabel=None)\n",
    "\n",
    "fig.suptitle(\"Data distribution - Salaries v. one factor\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Figure 3 & 4: Salary Distributions by Education Level and Years of Experience\n",
    "g = sns.displot(data=df_salaries_cleaned, x=\"Salary\", hue=\"Education Level\", multiple=\"stack\")\n",
    "g.set(title='Salary Distribution By Education Level', xlabel=None)\n",
    "plt.xticks(rotation=45)\n",
    "g = sns.displot(data=df_salaries_cleaned, x=\"Salary\", hue=\"Years of Experience\", multiple=\"stack\")\n",
    "g.set(title=\"Salary Distribution By Years of Experience\", xlabel=None)\n",
    "p = plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test multiple different feature combinations\n",
    "df_salaries_cleaned_edulvl = df_salaries_cleaned\n",
    "df_salaries_cleaned_edulvl[\"Education Level\"] = df_salaries_cleaned[\"Education Level\"].replace(\"High School\", 1)\n",
    "df_salaries_cleaned_edulvl[\"Education Level\"] = df_salaries_cleaned[\"Education Level\"].replace(\"Bachelor's\", 2)\n",
    "df_salaries_cleaned_edulvl[\"Education Level\"] = df_salaries_cleaned[\"Education Level\"].replace(\"Master's\", 3)\n",
    "df_salaries_cleaned_edulvl[\"Education Level\"] = df_salaries_cleaned[\"Education Level\"].replace(\"PhD\", 4)\n",
    "\n",
    "# Multivariate Salary Model with Education Level and Years of Experience\n",
    "X = df_salaries_cleaned_edulvl[[\"Education Level\", \"Years of Experience\"]].values.reshape(-1,2)\n",
    "Y = df_salaries_cleaned_edulvl[\"Salary\"]\n",
    "\n",
    "x = X[:, 0]\n",
    "y = X[:, 1]\n",
    "z = Y\n",
    "x_pred = np.linspace(0, 4)\n",
    "y_pred = np.linspace(0, 35)\n",
    "xx_pred, yy_pred = np.meshgrid(x_pred, y_pred)\n",
    "model_viz = np.array([xx_pred.flatten(), yy_pred.flatten()]).T\n",
    "\n",
    "ols = LinearRegression()\n",
    "model = ols.fit(X, Y)\n",
    "predicted = model.predict(model_viz)\n",
    "\n",
    "r2 = model.score(X, Y)\n",
    "plt.style.use(\"default\")\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "ax1 = fig.add_subplot(131, projection=\"3d\")\n",
    "ax2 = fig.add_subplot(132, projection=\"3d\")\n",
    "ax3 = fig.add_subplot(133, projection=\"3d\")\n",
    "\n",
    "axes = [ax1, ax2, ax3]\n",
    "\n",
    "for ax in axes:\n",
    "    ax.plot(x, y, z, color=\"k\", zorder=15, linestyle=\"none\", marker=\"o\", alpha=0.01)\n",
    "    ax.scatter(xx_pred.flatten(), yy_pred.flatten(), predicted, facecolor=(0,0,0,0), s=5, edgecolor=\"#70b3f0\")\n",
    "    ax.set_xlabel(\"Education Level\", fontsize=12)\n",
    "    ax.set_ylabel(\"Years of Experience\", fontsize=12)\n",
    "    ax.set_zlabel(\"Salary\", fontsize=12)\n",
    "\n",
    "ax1.view_init(elev=28, azim=120)\n",
    "ax2.view_init(elev=4, azim=114)\n",
    "ax3.view_init(elev=60, azim=165)\n",
    "\n",
    "fig.suptitle(\"$R^2 = %.2f$\" % r2, fontsize=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Multivariate Salary Model with Age and Years of Experience\n",
    "X = df_salaries_cleaned[[\"Age\", \"Years of Experience\"]].values.reshape(-1,2)\n",
    "Y = df_salaries_cleaned[\"Salary\"]\n",
    "\n",
    "x = X[:, 0]\n",
    "y = X[:, 1]\n",
    "z = Y\n",
    "\n",
    "x_pred = np.linspace(0,62)\n",
    "y_pred = np.linspace(0, 35)\n",
    "xx_pred, yy_pred = np.meshgrid(x_pred, y_pred)\n",
    "model_viz = np.array([xx_pred.flatten(), yy_pred.flatten()]).T\n",
    "\n",
    "ols = LinearRegression()\n",
    "model = ols.fit(X, Y)\n",
    "predicted = model.predict(model_viz)\n",
    "\n",
    "r2 = model.score(X, Y)\n",
    "plt.style.use(\"default\")\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "ax1 = fig.add_subplot(131, projection=\"3d\")\n",
    "ax2 = fig.add_subplot(132, projection=\"3d\")\n",
    "ax3 = fig.add_subplot(133, projection=\"3d\")\n",
    "\n",
    "axes = [ax1, ax2, ax3]\n",
    "\n",
    "for ax in axes:\n",
    "    ax.plot(x, y, z, color=\"k\", zorder=15, linestyle=\"none\", marker=\"o\", alpha=0.01)\n",
    "    ax.scatter(xx_pred.flatten(), yy_pred.flatten(), predicted, facecolor=(0,0,0,0), s=5, edgecolor='#70b3f0')\n",
    "    ax.set_xlabel(\"Age\", fontsize=12)\n",
    "    ax.set_ylabel(\"Years of Experience\", fontsize=12)\n",
    "    ax.set_zlabel(\"Salary\", fontsize=12)\n",
    "\n",
    "ax1.view_init(elev=28, azim=120)\n",
    "ax2.view_init(elev=4, azim=114)\n",
    "ax3.view_init(elev=60, azim=165)\n",
    "\n",
    "fig.suptitle(\"$R^2 = %.2f$\" % r2, fontsize=20)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate categorical and numerical columns\n",
    "categorical_columns = [\"Gender\", \"Education Level\", \"Job Title\"]\n",
    "numerical_columns = [\"Age\", \"Years of Experience\"]\n",
    "\n",
    "# separate the data into features and target values\n",
    "X_data = df_salaries_cleaned[[\"Age\", \"Gender\", \"Education Level\", \"Job Title\", \"Years of Experience\"]]\n",
    "y_data = df_salaries_cleaned[\"Salary\"]\n",
    "\n",
    "# split the data into test and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# transform table to standardize columns\n",
    "ct = make_column_transformer(\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), categorical_columns),\n",
    "    (StandardScaler(), numerical_columns),\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tuning pipeline\n",
    "pipeline_lin_initial = make_pipeline(\n",
    "    ct,\n",
    "    SelectKBest(score_func=f_regression),\n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "# hyperparameters to tune\n",
    "param_grid_lin = {\n",
    "    \"selectkbest__k\": [1, 2, 3, 4, 5],\n",
    "}\n",
    "\n",
    "# create an exhaustive search using cross validation\n",
    "grid_search_lin = GridSearchCV(pipeline_lin_initial, param_grid_lin, cv=5, scoring=\"r2\")\n",
    "\n",
    "# perform exhaustive search to tune hyperparameters\n",
    "grid_search_lin.fit(X_data, y_data)\n",
    "\n",
    "print(\"Best Features:\", grid_search_lin.best_estimator_.feature_names_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model pipeline\n",
    "pipeline_lin_tuned = make_pipeline(\n",
    "    ct,\n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "# train model on training data\n",
    "pipeline_lin_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict salaries on testing data\n",
    "y_pred_linear = pipeline_lin_tuned.predict(X_test)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test, y_pred_linear))\n",
    "print(\"Root Mean Squared Error (RMSE):\", math.sqrt(mean_squared_error(y_test, y_pred_linear)))\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual Salaries vs Predicted Salaries Graph\n",
    "\n",
    "# table consisting of actual salaries\n",
    "df_actual = pd.DataFrame({\"x\": [n for n in range(len(y_test))]})\n",
    "df_actual[\"y\"] = list(y_test)\n",
    "\n",
    "# table consisting of predicted salaries\n",
    "df_predicted = pd.DataFrame({\"x\": [n for n in range(len(y_pred_linear))]})\n",
    "df_predicted[\"y\"] = y_pred_linear\n",
    "\n",
    "# create shared plot\n",
    "ax = plt.gca()\n",
    "\n",
    "# plot actual and predicted salaries\n",
    "df_actual.plot(x=\"x\", y=\"y\", kind=\"line\", color=\"blue\", label=\"Actual\", ax=ax, alpha=0.5)\n",
    "df_predicted.plot(x=\"x\", y=\"y\", kind=\"line\", color=\"green\", label=\"Predicted\", ax=ax, alpha=0.5)\n",
    "\n",
    "# set labels\n",
    "ax.set_xlabel(\"Index\")\n",
    "ax.set_ylabel(\"Salary\")\n",
    "ax.set_title(\"Actual Salaries vs Predicted Salaries for Linear Regression\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute Error Graph\n",
    "\n",
    "# take the difference between each actual and predicted\n",
    "df_diff = pd.DataFrame({\"x\": [n for n in range(len(y_test))]})\n",
    "df_diff[\"y\"] = y_test.to_numpy() - y_pred_linear\n",
    "\n",
    "# apply absolute value\n",
    "df_diff = df_diff.apply(abs)\n",
    "\n",
    "# set labels\n",
    "plt.plot(df_diff[\"x\"], df_diff[\"y\"], color=\"purple\", alpha=0.5)\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.title(\"Absolute Error for Linear Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **K-Nearest Neighbors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tuning pipeline\n",
    "pipeline_knn_initial = make_pipeline(\n",
    "    ct,\n",
    "    SelectKBest(score_func=f_regression),\n",
    "    KNeighborsRegressor(metric=\"euclidean\")\n",
    ")\n",
    "\n",
    "# hyperparameters to tune\n",
    "param_grid_knn = {\n",
    "    \"selectkbest__k\": [1, 2, 3, 4, 5],\n",
    "    \"kneighborsregressor__n_neighbors\": [n for n in range(1, 10)]\n",
    "}\n",
    "\n",
    "# create an exhaustive search using cross validation\n",
    "grid_search_knn = GridSearchCV(pipeline_knn_initial, param_grid_knn, cv=5, scoring=\"r2\")\n",
    "\n",
    "# perform exhaustive search to tune hyperparameters\n",
    "grid_search_knn.fit(X_data, y_data)\n",
    "\n",
    "print(\"Best N-Neighbors:\", grid_search_knn.best_params_[\"kneighborsregressor__n_neighbors\"])\n",
    "print(\"Best Features:\", grid_search_knn.best_estimator_.feature_names_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model pipeline\n",
    "pipeline_knn_tuned = make_pipeline(\n",
    "    ct,\n",
    "    KNeighborsRegressor(n_neighbors=9, metric=\"euclidean\")\n",
    ")\n",
    "\n",
    "# train model on training data\n",
    "pipeline_knn_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict salaries on testing data\n",
    "y_pred_knn = pipeline_knn_tuned.predict(X_test)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test, y_pred_knn))\n",
    "print(\"Root Mean Squared Error (RMSE):\", math.sqrt(mean_squared_error(y_test, y_pred_knn)))\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual Salaries vs Predicted Salaries Graph\n",
    "\n",
    "# table consisting of actual salaries\n",
    "df_actual = pd.DataFrame({\"x\": [n for n in range(len(y_test))]})\n",
    "df_actual[\"y\"] = list(y_test)\n",
    "\n",
    "# table consisting of predicted salaries\n",
    "df_predicted = pd.DataFrame({\"x\": [n for n in range(len(y_pred_knn))]})\n",
    "df_predicted[\"y\"] = y_pred_knn\n",
    "\n",
    "# create shared plot\n",
    "ax = plt.gca()\n",
    "\n",
    "# plot actual and predicted salaries\n",
    "df_actual.plot(x=\"x\", y=\"y\", kind=\"line\", color=\"blue\", label=\"Actual\", ax=ax, alpha=0.5)\n",
    "df_predicted.plot(x=\"x\", y=\"y\", kind=\"line\", color=\"green\", label=\"Predicted\", ax=ax, alpha=0.5)\n",
    "\n",
    "# set labels\n",
    "ax.set_xlabel(\"Index\")\n",
    "ax.set_ylabel(\"Salary\")\n",
    "ax.set_title(\"Actual Salaries vs Predicted Salaries for KNN\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute Error Graph\n",
    "\n",
    "# take the difference between each actual and predicted\n",
    "df_diff = pd.DataFrame({\"x\": [n for n in range(len(y_test))]})\n",
    "df_diff[\"y\"] = y_test.to_numpy() - y_pred_knn\n",
    "\n",
    "# apply absolute value\n",
    "df_diff = df_diff.apply(abs)\n",
    "\n",
    "# set labels\n",
    "plt.plot(df_diff[\"x\"], df_diff[\"y\"], color=\"purple\", alpha=0.5)\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.title(\"Absolute Error for KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model pipeline\n",
    "pipeline_rf_initial = make_pipeline(\n",
    "    ct,\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42)\n",
    ")\n",
    "\n",
    "# Define the hyperparameters grid for the Random Forest\n",
    "param_grid_rf = {\n",
    "    \"randomforestregressor__n_estimators\": [100, 200],  # Number of trees in the forest\n",
    "    \"randomforestregressor__max_depth\": [None, 10, 20, 30],  # Maximum depth of the trees\n",
    "    \"randomforestregressor__min_samples_split\": [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    \"randomforestregressor__min_samples_leaf\": [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the pipeline and parameter grid\n",
    "grid_search_rf = GridSearchCV(pipeline_rf_initial, param_grid_rf, cv=5, scoring=\"r2\", verbose=1)\n",
    "\n",
    "# Assuming X_data and y_data are your features and target variable\n",
    "grid_search_rf.fit(X_data, y_data)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search_rf.best_params_)\n",
    "print(\"Best Features:\", grid_search_rf.best_estimator_.feature_names_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model pipeline\n",
    "pipeline_rf_tuned = make_pipeline(\n",
    "    ct,\n",
    "    RandomForestRegressor(max_depth=30, min_samples_leaf=1, min_samples_split=5,n_estimators=200, random_state=42)\n",
    ")\n",
    "\n",
    "# train model on training data\n",
    "pipeline_rf_tuned.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict salaries on testing data\n",
    "y_pred_rf = pipeline_rf_tuned.predict(X_test)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test, y_pred_rf))\n",
    "print(\"Root Mean Squared Error (RMSE):\", math.sqrt(mean_squared_error(y_test, y_pred_rf)))\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for extracting the features used from a pipeline's column transformer\n",
    "def get_feature_names(column_transformer):\n",
    "    \"\"\"Get feature names from a ColumnTransformer.\"\"\"\n",
    "    output_features = []\n",
    "\n",
    "    # loop through each transformer within the ColumnTransformer\n",
    "    for name, estimator, columns in column_transformer.transformers_:\n",
    "        if name == \"remainder\":  # Skip the 'remainder' transformer\n",
    "            continue\n",
    "        # handle one-hot encoded features\n",
    "        if hasattr(estimator, \"categories_\"):\n",
    "            for i, category in enumerate(estimator.categories_):\n",
    "                output_features.extend([f\"{columns[i]}_{cat}\" for cat in category])\n",
    "        # handle other transformers (e.g., scaling numerical features)\n",
    "        else:\n",
    "            output_features.extend(columns)\n",
    "\n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = pipeline_rf_tuned.named_steps[\"randomforestregressor\"]\n",
    "tree = random_forest_model.estimators_[0]\n",
    "\n",
    "# extract feature names\n",
    "transformed_feature_names = get_feature_names(pipeline_rf_tuned.named_steps[\"columntransformer\"])\n",
    "\n",
    "# export the tree to a DOT format\n",
    "dot_data = export_graphviz(tree, out_file=None, \n",
    "                           feature_names=transformed_feature_names, \n",
    "                           filled=True, rounded=True, \n",
    "                           special_characters=True, max_depth=3)\n",
    "\n",
    "# render the DOT data\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"decision_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual Salaries vs Predicted Salaries Graph\n",
    "\n",
    "# table consisting of actual salaries\n",
    "df_actual = pd.DataFrame({\"x\": [n for n in range(len(y_test))]})\n",
    "df_actual[\"y\"] = list(y_test)\n",
    "\n",
    "# table consisting of predicted salaries\n",
    "df_predicted = pd.DataFrame({\"x\": [n for n in range(len(y_pred_rf))]})\n",
    "df_predicted[\"y\"] = y_pred_rf\n",
    "\n",
    "# create shared plot\n",
    "ax = plt.gca()\n",
    "\n",
    "# plot actual and predicted salaries\n",
    "df_actual.plot(x=\"x\", y=\"y\", kind=\"line\", color=\"blue\", label=\"Actual\", ax=ax, alpha=0.65)\n",
    "df_predicted.plot(x=\"x\", y=\"y\", kind=\"line\", color=\"green\", label=\"Predicted\", ax=ax, alpha=0.65)\n",
    "\n",
    "# set labels\n",
    "ax.set_xlabel(\"Index\")\n",
    "ax.set_ylabel(\"Salary\")\n",
    "ax.set_title(\"Actual Salaries vs Predicted Salaries for Random Forest Model\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute Error Graph\n",
    "\n",
    "# take the difference between each actual and predicted\n",
    "df_diff = pd.DataFrame({\"x\": [n for n in range(len(y_test))]})\n",
    "df_diff[\"y\"] = y_test.to_numpy() - y_pred_rf\n",
    "\n",
    "# apply absolute value\n",
    "df_diff = df_diff.apply(abs)\n",
    "\n",
    "# set labels\n",
    "plt.plot(df_diff[\"x\"], df_diff[\"y\"], color=\"purple\", alpha=0.65)\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.title(\"Absolute Error for Random Forest Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Example Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame({\n",
    "    \"Age\": [50],\n",
    "    \"Gender\": [\"Male\"],\n",
    "    \"Education Level\": [\"PhD\"],\n",
    "    \"Job Title\": [\"Software Developer\"],\n",
    "    \"Years of Experience\": [5]\n",
    "})\n",
    "\n",
    "y_pred = pipeline_rf_tuned.predict(X_test)\n",
    "\n",
    "print(\"Predicted Salary:\", y_pred[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
